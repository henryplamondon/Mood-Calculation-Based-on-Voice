{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.image as mpimg\n",
        "from natsort import natsorted\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "6466ZDJDCve4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wypgHFWlV8R4",
        "outputId": "1c16e2f1-2908-416a-db18-3088afe1943b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Opening and Visualizing Files"
      ],
      "metadata": {
        "id": "xSgrnMcOHSmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TO DO\n",
        "# Figure out how to automate importing files from Google Drive and opening them into a pd.DataFrame"
      ],
      "metadata": {
        "id": "CEL3IsXWH6xB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Open WAV file samples and sampling rate (put in loop to extract files as new variables)\n",
        "\n",
        "# Pre-processing here (equalizer function)\n",
        "\n",
        "# Add variables to dataloader\n",
        "\n",
        "\n",
        "\n",
        "# Folder with multiple files\n",
        "dir = '/content/drive/Shareddrives/BE5740/Dataset/All files/'\n",
        "\n",
        "# Initialize full_info list for data to turn into DataFrame\n",
        "full_info = []\n",
        "\n",
        "# Iterate over all files within main folder\n",
        "for main_folder in tqdm(os.listdir(dir)):\n",
        "  set_folder = dir + str(main_folder)   # Extract name of the set of trials folder\n",
        "\n",
        "  # Iterate over folder of set of trials\n",
        "  for folder in tqdm(os.listdir(set_folder)):\n",
        "    ind_folder = str(set_folder) + '/' + str(folder)   # Extract name of the individual folder\n",
        "\n",
        "    # Iterate over all files in single trial folder\n",
        "    for file in os.listdir(ind_folder):\n",
        "\n",
        "      # Determine if it's an audio file\n",
        "      if file.endswith(\".wav\"):\n",
        "\n",
        "        sample_rate, samples = wavfile.read(ind_folder + '/' + str(file)) # read file and extract info\n",
        "\n",
        "        # Set variables for characteristics of the spectrogram\n",
        "        frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)\n",
        "\n",
        "        trial_info = {'Trial': str(file)[0:-4], 'Frequency': frequencies, 'Raw Data': samples}\n",
        "\n",
        "        full_info.append(trial_info)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(full_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVj-B-KVG0eQ",
        "outputId": "67d5fa9d-86e4-4966-c382-c9746025ba0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/4 [00:00<?, ?it/s]\n",
            "  0%|          | 0/62 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/62 [00:00<00:41,  1.46it/s]\u001b[A\n",
            "  3%|▎         | 2/62 [00:01<00:46,  1.28it/s]\u001b[A\n",
            "  5%|▍         | 3/62 [00:02<00:41,  1.41it/s]\u001b[A\n",
            "  6%|▋         | 4/62 [00:02<00:43,  1.34it/s]\u001b[A\n",
            "  8%|▊         | 5/62 [00:03<00:43,  1.31it/s]\u001b[A\n",
            " 10%|▉         | 6/62 [00:04<00:41,  1.35it/s]\u001b[A\n",
            " 11%|█▏        | 7/62 [00:05<00:38,  1.42it/s]\u001b[A\n",
            " 13%|█▎        | 8/62 [00:05<00:40,  1.34it/s]\u001b[A\n",
            " 15%|█▍        | 9/62 [00:06<00:39,  1.33it/s]\u001b[A\n",
            " 16%|█▌        | 10/62 [00:07<00:47,  1.09it/s]\u001b[A\n",
            " 18%|█▊        | 11/62 [00:08<00:45,  1.13it/s]\u001b[A\n",
            " 19%|█▉        | 12/62 [00:09<00:41,  1.20it/s]\u001b[A\n",
            " 21%|██        | 13/62 [00:09<00:35,  1.39it/s]\u001b[A\n",
            " 23%|██▎       | 14/62 [00:10<00:33,  1.45it/s]\u001b[A\n",
            " 24%|██▍       | 15/62 [00:10<00:28,  1.67it/s]\u001b[A\n",
            " 26%|██▌       | 16/62 [00:11<00:24,  1.86it/s]\u001b[A\n",
            " 27%|██▋       | 17/62 [00:12<00:27,  1.62it/s]\u001b[A\n",
            " 29%|██▉       | 18/62 [00:12<00:27,  1.63it/s]\u001b[A\n",
            " 31%|███       | 19/62 [00:13<00:26,  1.65it/s]\u001b[A\n",
            " 32%|███▏      | 20/62 [00:13<00:25,  1.68it/s]\u001b[A\n",
            " 34%|███▍      | 21/62 [00:14<00:25,  1.59it/s]\u001b[A\n",
            " 35%|███▌      | 22/62 [00:15<00:25,  1.55it/s]\u001b[A\n",
            " 37%|███▋      | 23/62 [00:15<00:25,  1.56it/s]\u001b[A\n",
            " 39%|███▊      | 24/62 [00:16<00:21,  1.76it/s]\u001b[A\n",
            " 40%|████      | 25/62 [00:16<00:19,  1.88it/s]\u001b[A\n",
            " 42%|████▏     | 26/62 [00:17<00:20,  1.74it/s]\u001b[A\n",
            " 44%|████▎     | 27/62 [00:17<00:19,  1.82it/s]\u001b[A\n",
            " 45%|████▌     | 28/62 [00:18<00:17,  1.91it/s]\u001b[A\n",
            " 47%|████▋     | 29/62 [00:19<00:17,  1.86it/s]\u001b[A\n",
            " 48%|████▊     | 30/62 [00:19<00:17,  1.79it/s]\u001b[A\n",
            " 50%|█████     | 31/62 [00:20<00:16,  1.89it/s]\u001b[A\n",
            " 52%|█████▏    | 32/62 [00:20<00:17,  1.76it/s]\u001b[A\n",
            " 53%|█████▎    | 33/62 [00:32<01:50,  3.81s/it]\u001b[A\n",
            " 55%|█████▍    | 34/62 [00:32<01:18,  2.79s/it]\u001b[A\n",
            " 56%|█████▋    | 35/62 [00:33<00:56,  2.11s/it]\u001b[A\n",
            " 58%|█████▊    | 36/62 [00:33<00:41,  1.58s/it]\u001b[A\n",
            " 60%|█████▉    | 37/62 [00:33<00:31,  1.27s/it]\u001b[A\n",
            " 61%|██████▏   | 38/62 [00:34<00:28,  1.20s/it]\u001b[A\n",
            " 63%|██████▎   | 39/62 [00:47<01:42,  4.47s/it]\u001b[A\n",
            " 65%|██████▍   | 40/62 [00:47<01:12,  3.27s/it]\u001b[A\n",
            " 66%|██████▌   | 41/62 [00:48<00:52,  2.48s/it]\u001b[A\n",
            " 68%|██████▊   | 42/62 [00:49<00:40,  2.01s/it]\u001b[A\n",
            " 69%|██████▉   | 43/62 [00:50<00:33,  1.76s/it]\u001b[A\n",
            " 71%|███████   | 44/62 [00:50<00:26,  1.45s/it]\u001b[A\n",
            " 73%|███████▎  | 45/62 [00:51<00:22,  1.30s/it]\u001b[A\n",
            " 74%|███████▍  | 46/62 [01:00<00:57,  3.58s/it]\u001b[A\n",
            " 76%|███████▌  | 47/62 [01:10<01:20,  5.37s/it]\u001b[A\n",
            " 77%|███████▋  | 48/62 [01:23<01:45,  7.56s/it]\u001b[A\n",
            " 79%|███████▉  | 49/62 [01:23<01:11,  5.50s/it]\u001b[A\n",
            " 81%|████████  | 50/62 [01:32<01:18,  6.51s/it]\u001b[A\n",
            " 82%|████████▏ | 51/62 [01:32<00:51,  4.68s/it]\u001b[A\n",
            " 84%|████████▍ | 52/62 [01:33<00:34,  3.50s/it]\u001b[A\n",
            " 85%|████████▌ | 53/62 [01:46<00:57,  6.42s/it]\u001b[A\n",
            " 87%|████████▋ | 54/62 [01:47<00:36,  4.61s/it]\u001b[A\n",
            " 89%|████████▊ | 55/62 [01:58<00:45,  6.44s/it]\u001b[A\n",
            " 90%|█████████ | 56/62 [02:15<00:58,  9.76s/it]\u001b[A\n",
            " 92%|█████████▏| 57/62 [02:21<00:43,  8.62s/it]\u001b[A\n",
            " 94%|█████████▎| 58/62 [02:26<00:30,  7.62s/it]\u001b[A\n",
            " 95%|█████████▌| 59/62 [02:27<00:16,  5.66s/it]\u001b[A\n",
            " 97%|█████████▋| 60/62 [02:46<00:18,  9.45s/it]\u001b[A\n",
            " 98%|█████████▊| 61/62 [02:46<00:06,  6.72s/it]\u001b[A\n",
            "100%|██████████| 62/62 [02:52<00:00,  2.79s/it]\n",
            " 25%|██▌       | 1/4 [02:52<08:38, 172.84s/it]\n",
            "  0%|          | 0/77 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1/77 [00:00<01:07,  1.13it/s]\u001b[A\n",
            "  3%|▎         | 2/77 [00:01<00:56,  1.33it/s]\u001b[A\n",
            "  4%|▍         | 3/77 [00:02<01:07,  1.09it/s]\u001b[A\n",
            "  5%|▌         | 4/77 [00:03<01:06,  1.11it/s]\u001b[A\n",
            "  6%|▋         | 5/77 [00:04<00:53,  1.34it/s]\u001b[A\n",
            "  8%|▊         | 6/77 [00:04<00:51,  1.37it/s]\u001b[A\n",
            "  9%|▉         | 7/77 [00:05<00:43,  1.60it/s]\u001b[A\n",
            " 10%|█         | 8/77 [00:05<00:41,  1.65it/s]\u001b[A\n",
            " 12%|█▏        | 9/77 [00:06<00:41,  1.62it/s]\u001b[A\n",
            " 13%|█▎        | 10/77 [00:07<00:47,  1.42it/s]\u001b[A\n",
            " 14%|█▍        | 11/77 [00:07<00:41,  1.60it/s]\u001b[A\n",
            " 16%|█▌        | 12/77 [00:08<00:37,  1.73it/s]\u001b[A\n",
            " 17%|█▋        | 13/77 [00:08<00:34,  1.88it/s]\u001b[A\n",
            " 18%|█▊        | 14/77 [00:09<00:34,  1.81it/s]\u001b[A\n",
            " 19%|█▉        | 15/77 [00:09<00:33,  1.85it/s]\u001b[A\n",
            " 21%|██        | 16/77 [00:10<00:34,  1.75it/s]\u001b[A\n",
            " 22%|██▏       | 17/77 [00:10<00:32,  1.84it/s]\u001b[A\n",
            " 23%|██▎       | 18/77 [00:11<00:33,  1.75it/s]\u001b[A\n",
            " 25%|██▍       | 19/77 [00:12<00:34,  1.70it/s]\u001b[A\n",
            " 26%|██▌       | 20/77 [00:12<00:34,  1.65it/s]\u001b[A\n",
            " 27%|██▋       | 21/77 [00:13<00:33,  1.68it/s]\u001b[A\n",
            " 29%|██▊       | 22/77 [00:14<00:35,  1.56it/s]\u001b[A\n",
            " 30%|██▉       | 23/77 [00:15<00:44,  1.22it/s]\u001b[A\n",
            " 31%|███       | 24/77 [00:15<00:39,  1.33it/s]\u001b[A\n",
            " 32%|███▏      | 25/77 [00:16<00:43,  1.18it/s]\u001b[A\n",
            " 34%|███▍      | 26/77 [00:17<00:39,  1.28it/s]\u001b[A\n",
            " 35%|███▌      | 27/77 [00:18<00:39,  1.25it/s]\u001b[A\n",
            " 38%|███▊      | 29/77 [00:19<00:30,  1.55it/s]\u001b[A\n",
            " 39%|███▉      | 30/77 [00:19<00:29,  1.59it/s]\u001b[A\n",
            " 40%|████      | 31/77 [00:21<00:37,  1.22it/s]\u001b[A\n",
            " 42%|████▏     | 32/77 [00:21<00:35,  1.28it/s]\u001b[A\n",
            " 43%|████▎     | 33/77 [00:22<00:30,  1.42it/s]\u001b[A\n",
            " 44%|████▍     | 34/77 [00:23<00:28,  1.50it/s]\u001b[A\n",
            " 45%|████▌     | 35/77 [00:23<00:26,  1.57it/s]\u001b[A\n",
            " 47%|████▋     | 36/77 [00:24<00:28,  1.44it/s]\u001b[A\n",
            " 48%|████▊     | 37/77 [00:25<00:27,  1.48it/s]\u001b[A\n",
            " 49%|████▉     | 38/77 [00:25<00:27,  1.42it/s]\u001b[A\n",
            " 51%|█████     | 39/77 [00:26<00:24,  1.52it/s]\u001b[A\n",
            " 52%|█████▏    | 40/77 [00:27<00:28,  1.31it/s]\u001b[A\n",
            " 53%|█████▎    | 41/77 [00:28<00:26,  1.37it/s]\u001b[A\n",
            " 55%|█████▍    | 42/77 [00:28<00:27,  1.25it/s]\u001b[A\n",
            " 56%|█████▌    | 43/77 [00:30<00:29,  1.14it/s]\u001b[A\n",
            " 57%|█████▋    | 44/77 [00:30<00:26,  1.23it/s]\u001b[A\n",
            " 58%|█████▊    | 45/77 [00:31<00:25,  1.26it/s]\u001b[A\n",
            " 60%|█████▉    | 46/77 [00:32<00:22,  1.36it/s]\u001b[A\n",
            " 61%|██████    | 47/77 [00:32<00:22,  1.31it/s]\u001b[A\n",
            " 64%|██████▎   | 49/77 [00:34<00:19,  1.44it/s]\u001b[A\n",
            " 65%|██████▍   | 50/77 [00:34<00:18,  1.44it/s]\u001b[A\n",
            " 66%|██████▌   | 51/77 [00:35<00:16,  1.53it/s]\u001b[A\n",
            " 68%|██████▊   | 52/77 [00:36<00:18,  1.32it/s]\u001b[A\n",
            " 69%|██████▉   | 53/77 [00:37<00:18,  1.31it/s]\u001b[A\n",
            " 70%|███████   | 54/77 [00:37<00:15,  1.47it/s]\u001b[A\n",
            " 71%|███████▏  | 55/77 [00:38<00:17,  1.27it/s]\u001b[A\n",
            " 73%|███████▎  | 56/77 [00:39<00:15,  1.39it/s]\u001b[A\n",
            " 74%|███████▍  | 57/77 [00:40<00:15,  1.28it/s]\u001b[A\n",
            " 75%|███████▌  | 58/77 [00:41<00:16,  1.17it/s]\u001b[A\n",
            " 77%|███████▋  | 59/77 [00:41<00:14,  1.25it/s]\u001b[A\n",
            " 78%|███████▊  | 60/77 [00:42<00:12,  1.33it/s]\u001b[A\n",
            " 79%|███████▉  | 61/77 [00:43<00:11,  1.40it/s]\u001b[A\n",
            " 81%|████████  | 62/77 [00:44<00:13,  1.11it/s]\u001b[A\n",
            " 82%|████████▏ | 63/77 [00:45<00:11,  1.23it/s]\u001b[A\n",
            " 84%|████████▍ | 65/77 [00:45<00:07,  1.67it/s]\u001b[A\n",
            " 86%|████████▌ | 66/77 [00:46<00:08,  1.35it/s]\u001b[A\n",
            " 87%|████████▋ | 67/77 [00:47<00:07,  1.37it/s]\u001b[A\n",
            " 88%|████████▊ | 68/77 [00:48<00:07,  1.25it/s]\u001b[A\n",
            " 90%|████████▉ | 69/77 [00:49<00:06,  1.23it/s]\u001b[A\n",
            " 91%|█████████ | 70/77 [00:50<00:05,  1.34it/s]\u001b[A\n",
            " 92%|█████████▏| 71/77 [00:50<00:04,  1.35it/s]\u001b[A\n",
            " 94%|█████████▎| 72/77 [00:51<00:03,  1.47it/s]\u001b[A\n",
            " 95%|█████████▍| 73/77 [00:51<00:02,  1.59it/s]\u001b[A\n",
            " 96%|█████████▌| 74/77 [00:52<00:01,  1.59it/s]\u001b[A\n",
            " 97%|█████████▋| 75/77 [00:53<00:01,  1.53it/s]\u001b[A\n",
            " 99%|█████████▊| 76/77 [00:53<00:00,  1.51it/s]\u001b[A\n",
            "100%|██████████| 77/77 [00:54<00:00,  1.41it/s]\n",
            " 50%|█████     | 2/4 [03:47<03:26, 103.29s/it]\n",
            "  0%|          | 0/81 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 2/81 [00:00<00:27,  2.86it/s]\u001b[A\n",
            "  4%|▎         | 3/81 [00:01<00:32,  2.39it/s]\u001b[A\n",
            "  5%|▍         | 4/81 [00:01<00:37,  2.06it/s]\u001b[A\n",
            "  6%|▌         | 5/81 [00:03<01:14,  1.02it/s]\u001b[A\n",
            "  7%|▋         | 6/81 [00:05<01:29,  1.20s/it]\u001b[A\n",
            "  9%|▊         | 7/81 [00:05<01:12,  1.02it/s]\u001b[A\n",
            " 10%|▉         | 8/81 [00:06<01:14,  1.02s/it]\u001b[A\n",
            " 11%|█         | 9/81 [00:07<01:09,  1.03it/s]\u001b[A\n",
            " 12%|█▏        | 10/81 [00:08<01:09,  1.03it/s]\u001b[A\n",
            " 14%|█▎        | 11/81 [00:09<00:56,  1.24it/s]\u001b[A\n",
            " 15%|█▍        | 12/81 [00:09<00:49,  1.39it/s]\u001b[A\n",
            " 16%|█▌        | 13/81 [00:10<00:42,  1.59it/s]\u001b[A\n",
            " 17%|█▋        | 14/81 [00:10<00:45,  1.46it/s]\u001b[A\n",
            " 19%|█▊        | 15/81 [00:11<00:40,  1.62it/s]\u001b[A\n",
            " 20%|█▉        | 16/81 [00:12<00:43,  1.51it/s]\u001b[A\n",
            " 21%|██        | 17/81 [00:13<00:49,  1.30it/s]\u001b[A\n",
            " 22%|██▏       | 18/81 [00:14<01:05,  1.04s/it]\u001b[A\n",
            " 23%|██▎       | 19/81 [00:15<00:53,  1.16it/s]\u001b[A\n",
            " 25%|██▍       | 20/81 [00:15<00:47,  1.28it/s]\u001b[A\n",
            " 26%|██▌       | 21/81 [00:16<00:44,  1.34it/s]\u001b[A\n",
            " 27%|██▋       | 22/81 [00:17<00:42,  1.38it/s]\u001b[A\n",
            " 28%|██▊       | 23/81 [00:19<01:05,  1.12s/it]\u001b[A\n",
            " 30%|██▉       | 24/81 [00:20<00:56,  1.00it/s]\u001b[A\n",
            " 31%|███       | 25/81 [00:20<00:53,  1.05it/s]\u001b[A\n",
            " 32%|███▏      | 26/81 [00:21<00:47,  1.15it/s]\u001b[A\n",
            " 33%|███▎      | 27/81 [00:21<00:39,  1.36it/s]\u001b[A\n",
            " 35%|███▍      | 28/81 [00:22<00:37,  1.40it/s]\u001b[A\n",
            " 36%|███▌      | 29/81 [00:23<00:36,  1.43it/s]\u001b[A\n",
            " 37%|███▋      | 30/81 [00:23<00:31,  1.63it/s]\u001b[A\n",
            " 38%|███▊      | 31/81 [00:24<00:33,  1.50it/s]\u001b[A\n",
            " 40%|███▉      | 32/81 [00:25<00:30,  1.61it/s]\u001b[A\n",
            " 41%|████      | 33/81 [00:25<00:30,  1.57it/s]\u001b[A\n",
            " 42%|████▏     | 34/81 [00:26<00:29,  1.57it/s]\u001b[A\n",
            " 43%|████▎     | 35/81 [00:27<00:34,  1.34it/s]\u001b[A\n",
            " 44%|████▍     | 36/81 [00:28<00:35,  1.26it/s]\u001b[A\n",
            " 46%|████▌     | 37/81 [00:29<00:34,  1.29it/s]\u001b[A\n",
            " 47%|████▋     | 38/81 [00:29<00:28,  1.51it/s]\u001b[A\n",
            " 48%|████▊     | 39/81 [00:30<00:27,  1.53it/s]\u001b[A\n",
            " 49%|████▉     | 40/81 [00:30<00:25,  1.62it/s]\u001b[A\n",
            " 51%|█████     | 41/81 [00:31<00:22,  1.74it/s]\u001b[A\n",
            " 52%|█████▏    | 42/81 [00:31<00:26,  1.48it/s]\u001b[A\n",
            " 53%|█████▎    | 43/81 [00:32<00:25,  1.51it/s]\u001b[A\n",
            " 54%|█████▍    | 44/81 [00:33<00:23,  1.60it/s]\u001b[A\n",
            " 56%|█████▌    | 45/81 [00:33<00:24,  1.49it/s]\u001b[A\n",
            " 57%|█████▋    | 46/81 [00:34<00:27,  1.26it/s]\u001b[A\n",
            " 58%|█████▊    | 47/81 [00:35<00:22,  1.48it/s]\u001b[A\n",
            " 59%|█████▉    | 48/81 [00:35<00:18,  1.77it/s]\u001b[A\n",
            " 60%|██████    | 49/81 [00:36<00:16,  1.95it/s]\u001b[A\n",
            " 62%|██████▏   | 50/81 [00:36<00:15,  2.00it/s]\u001b[A\n",
            " 63%|██████▎   | 51/81 [00:37<00:14,  2.03it/s]\u001b[A\n",
            " 64%|██████▍   | 52/81 [00:37<00:15,  1.92it/s]\u001b[A\n",
            " 65%|██████▌   | 53/81 [00:39<00:23,  1.17it/s]\u001b[A\n",
            " 67%|██████▋   | 54/81 [00:39<00:20,  1.30it/s]\u001b[A\n",
            " 68%|██████▊   | 55/81 [00:40<00:18,  1.44it/s]\u001b[A\n",
            " 69%|██████▉   | 56/81 [00:40<00:15,  1.57it/s]\u001b[A\n",
            " 70%|███████   | 57/81 [00:41<00:14,  1.67it/s]\u001b[A\n",
            " 72%|███████▏  | 58/81 [00:42<00:14,  1.63it/s]\u001b[A\n",
            " 73%|███████▎  | 59/81 [00:42<00:12,  1.75it/s]\u001b[A\n",
            " 74%|███████▍  | 60/81 [00:43<00:12,  1.71it/s]\u001b[A\n",
            " 75%|███████▌  | 61/81 [00:44<00:14,  1.41it/s]\u001b[A\n",
            " 77%|███████▋  | 62/81 [00:44<00:11,  1.64it/s]\u001b[A\n",
            " 78%|███████▊  | 63/81 [00:44<00:10,  1.79it/s]\u001b[A\n",
            " 79%|███████▉  | 64/81 [00:45<00:10,  1.65it/s]\u001b[A\n",
            " 80%|████████  | 65/81 [00:46<00:09,  1.62it/s]\u001b[A\n",
            " 81%|████████▏ | 66/81 [00:47<00:10,  1.49it/s]\u001b[A\n",
            " 83%|████████▎ | 67/81 [00:48<00:13,  1.01it/s]\u001b[A\n",
            " 84%|████████▍ | 68/81 [00:49<00:11,  1.10it/s]\u001b[A\n",
            " 85%|████████▌ | 69/81 [00:50<00:09,  1.21it/s]\u001b[A\n",
            " 86%|████████▋ | 70/81 [00:50<00:08,  1.34it/s]\u001b[A\n",
            " 88%|████████▊ | 71/81 [00:51<00:07,  1.32it/s]\u001b[A\n",
            " 89%|████████▉ | 72/81 [00:52<00:07,  1.19it/s]\u001b[A\n",
            " 90%|█████████ | 73/81 [00:53<00:06,  1.24it/s]\u001b[A\n",
            " 91%|█████████▏| 74/81 [00:54<00:07,  1.04s/it]\u001b[A\n",
            " 94%|█████████▍| 76/81 [00:55<00:03,  1.44it/s]\u001b[A\n",
            " 95%|█████████▌| 77/81 [00:56<00:02,  1.41it/s]\u001b[A\n",
            " 98%|█████████▊| 79/81 [00:56<00:01,  1.86it/s]\u001b[A\n",
            " 99%|█████████▉| 80/81 [00:57<00:00,  1.69it/s]\u001b[A\n",
            "100%|██████████| 81/81 [00:58<00:00,  1.38it/s]\n",
            " 75%|███████▌  | 3/4 [04:46<01:22, 82.92s/it] \n",
            "  0%|          | 0/52 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/52 [00:00<00:38,  1.33it/s]\u001b[A\n",
            "  4%|▍         | 2/52 [00:01<00:29,  1.72it/s]\u001b[A\n",
            "  6%|▌         | 3/52 [00:01<00:28,  1.72it/s]\u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "-vCb6UoFtQd_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "be01c17d-e255-41ad-b28c-2b16eeb8ae59"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-00cf07b74dcd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Using One File\n",
        "file_name = '/content/drive/Shareddrives/BE5740/Dataset/All files/641-718/718_P/718_AUDIO.wav'\n",
        "sample_rate, samples = wavfile.read(file_name)\n",
        "\n",
        "# Set variables for characteristics of the spectrogram\n",
        "frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)"
      ],
      "metadata": {
        "id": "NLuzSSOioiwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing out different filters and validating with spectrogram (find way to automate putting variables through filter and saving as new\n",
        "# variables))\n",
        "# We should figure out which frequencies human voices are generally at and filter everything outside of that out (AKA none of these\n",
        "# filters are doing much and I don't want to filter out the actual signal)\n",
        "\n",
        "### TO DO\n",
        "\n",
        "# Low pass butterworth filter\n",
        "b, a = signal.butter(3, 0.05)\n",
        "zi = signal.lfilter_zi(b, a)\n",
        "z, _ = signal.lfilter(b, a, samples, zi=zi*samples[0])\n",
        "z2, _ = signal.lfilter(b, a, z, zi=zi*z[0])\n",
        "y_lp_bw = signal.filtfilt(b, a, samples)\n",
        "\n",
        "# Notch filter\n",
        "fs = sample_rate  # Sample frequency (Hz)\n",
        "f0 = 10  # Frequency to be removed from signal (Hz)\n",
        "Q = 30.0  # Quality factor\n",
        "b, a = signal.iirnotch(f0, Q, fs)\n",
        "y_iirnotch = signal.filtfilt(b, a, samples)"
      ],
      "metadata": {
        "id": "RAxZkwfREMKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the spectrogram data to visualize\n",
        "plt.specgram(samples[int(1e6):int(1e6) + sample_rate * 2])\n",
        "cbar = plt.colorbar(label = 'Amplitude (dB)')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.xlabel('Time [sec]')\n",
        "plt.title(f'Spectrogram of {file_name[:-4]} file')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xLUZ3aRqLBRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the spectrogram with different filters\n",
        "# COMMENT HERE WHICH FILTER IS BEST\n",
        "filter = 'Lowpass Butterworth Filter'\n",
        "plt.specgram(y_lp_bw[int(1e6):int(1e6) + sample_rate * 2])\n",
        "cbar = plt.colorbar(label = 'Amplitude (dB)')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.xlabel('Time [sec]')\n",
        "plt.title(f'Spectrogram of {file_name[-13:-4]} file with {filter} applied')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mDshOuAcOS8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.magnitude_spectrum(samples)\n",
        "plt.title(f'Magnitude Spectrum of {file_name[:-4]} file')"
      ],
      "metadata": {
        "id": "GRnhLOrrLyN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open, Visualize, and Create pd.DataFrames out of CSV Files Here"
      ],
      "metadata": {
        "id": "9YAVqN6ZHjv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change path here for file\n",
        "file_path = '/content/drive/Shareddrives/BE5740/Dataset/All files/461-640/462/462_OpenFace2.1.0_Pose_gaze_AUs.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "OgYgyVIYZCbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 30 samples is 1 second so iterate over 120 samples for 4 seconds\n",
        "four_sec = 120\n",
        "\n",
        "expressions = df[df.columns[18:-1]]\n",
        "\n",
        "for i in range(math.ceil(len(df) / 120)):\n",
        "  temp = expressions[i * four_sec:(i+1) * four_sec]\n",
        "  col_mean = pd.DataFrame(temp.mean()).T\n",
        "  col = col_mean.max().idxmax()\n",
        "  print(col)"
      ],
      "metadata": {
        "id": "1HqR4kW8H3Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Automate looping through CSV files and creating ground truth \"happy\" or \"sad\" score based on average facial expression\n",
        "## over 4 seconds in each video. Use this in conjunction with 4 seconds of spectrogram information to train the neural net"
      ],
      "metadata": {
        "id": "syUVp-BlaKeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Pipeline Here"
      ],
      "metadata": {
        "id": "BPIA3WIvHZ9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Predictions Here"
      ],
      "metadata": {
        "id": "8y1EvI3SHeQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_ids = []   # These are the image ids of the images that we will be using for training\n",
        "val_image_ids = []     # These are the image ids of the images that we will be using for validation\n",
        "test_image_ids = []    # These are the image ids of the images that we will be using for testing\n",
        "\n",
        "# train_image_ids\n",
        "\n",
        "while(1):\n",
        "    ran_num = np.random.randint(low = 0, high = 1803460) # we should change the \"high\"\n",
        "                                          # number to the amount of samples we have for indexing purposes\n",
        "    if ran_num not in train_image_ids:\n",
        "        train_image_ids.append(ran_num)\n",
        "    if len(train_image_ids) == 10:   # Can change this number to how many images we want in training\n",
        "        break\n",
        "\n",
        "# val_image_ids\n",
        "\n",
        "while(1):\n",
        "    ran_num = np.random.randint(low = 0, high = 1803460)\n",
        "    if ran_num not in train_image_ids and ran_num not in val_image_ids:\n",
        "        val_image_ids.append(ran_num)\n",
        "    if len(val_image_ids) == 10:   # Can change this number to how many images we want in val\n",
        "        break\n",
        "\n",
        "# test_imge_ids\n",
        "\n",
        "while(1):\n",
        "    ran_num = np.random.randint(low = 0, high = 1803460)\n",
        "    if ran_num not in train_image_ids and ran_num not in val_image_ids and ran_num not in test_image_ids:\n",
        "        test_image_ids.append(ran_num)\n",
        "    if len(test_image_ids) == 5:   # Can change this number to how many images we want in testing\n",
        "        break\n",
        "\n",
        "train_image_ids = torch.tensor(train_image_ids)  # Converting train_image_ids list to a tensor\n",
        "val_image_ids = torch.tensor(val_image_ids)      # Converting val_image_ids list to a tensor\n",
        "test_image_ids = torch.tensor(test_image_ids)    # Converting test_image_ids list to a tensor\n",
        "\n",
        "\n",
        "train_images = torch.utils.data.Subset(dataset=data, indices=train_image_ids)    # Getting subset of images using these 5000 train_image_ids\n",
        "val_images = torch.utils.data.Subset(dataset=data, indices=val_image_ids)        # Getting subset of images using these 500 val_image_ids\n",
        "test_images = torch.utils.data.Subset(dataset=data, indices=test_image_ids)      # Getting subset of images using these 500 test_image_ids"
      ],
      "metadata": {
        "id": "H1D9KNzvmLbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starting DataLoader and CNN Here"
      ],
      "metadata": {
        "id": "gd00-e5c5fXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pic = '/content/drive/Shareddrives/BE5740/Dataset/spectrograms/380_seg_489.png'\n",
        "img = mpimg.imread(pic)\n",
        "#plt.imshow(img)\n",
        "#plt.show()\n",
        "img"
      ],
      "metadata": {
        "id": "iYQVHAJc6tWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spec_dir = '/content/drive/Shareddrives/BE5740/Dataset/spectrograms/'\n",
        "\n",
        "# Initialize full_info list for data to turn into DataFrame\n",
        "spectrograms = {'Spectrogram': [], 'Label': []}\n",
        "\n",
        "# Iterate over all spectrograms within spectrogram folder\n",
        "for spectrogram in tqdm(os.listdir(spec_dir)):\n",
        "  spectrograms['Spectrogram'].append(spectrogram)\n",
        "\n",
        "\n",
        "spectrograms['Spectrogram'] = natsorted(spectrograms['Spectrogram'])"
      ],
      "metadata": {
        "id": "cNEvm87s55WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mood_dir = '/content/drive/Shareddrives/BE5740/Dataset/mood/'\n",
        "\n",
        "csv = []\n",
        "\n",
        "for moods in tqdm(os.listdir(mood_dir)):\n",
        "  csv.append(moods)\n",
        "  #spectrograms['Label'].append(pd.read_csv(moods))\n",
        "\n",
        "csv = natsorted(csv)\n",
        "\n",
        "for val in tqdm(csv):\n",
        "  moods = pd.read_csv(mood_dir + val)\n",
        "  for index, row in moods.iterrows():\n",
        "    if row['filename'][0:-4] + '.png' in spectrograms['Spectrogram']:\n",
        "      spectrograms['Label'].append(row['label'])"
      ],
      "metadata": {
        "id": "_J4dKpRcA6Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_dir = '/content/drive/Shareddrives/BE5740/Dataset/spectrograms_zip/spectrograms.zip'\n",
        "\n",
        "zip = zipfile.ZipFile(zip_dir)\n",
        "images = natsorted(zip.namelist())\n",
        "\n",
        "imgzip = zipfile.ZipFile(zip_dir)\n",
        "inflist = imgzip.infolist()\n",
        "\n",
        "ifile = imgzip.open(images[0])\n",
        "img = Image.open(ifile)\n",
        "display(img)"
      ],
      "metadata": {
        "id": "T_blA3yUe3Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = []\n",
        "\n",
        "zip_dir = '/content/drive/Shareddrives/BE5740/Dataset/spectrograms_zip/spectrograms.zip'\n",
        "\n",
        "zip = zipfile.ZipFile(zip_dir)\n",
        "images = natsorted(zip.namelist())\n",
        "\n",
        "imgzip = zipfile.ZipFile(zip_dir)\n",
        "inflist = imgzip.infolist()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.PILToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "for pic in tqdm(images):\n",
        "  ifile = imgzip.open(pic)\n",
        "  img = Image.open(ifile)\n",
        "  img_tensor = transform(img)\n",
        "  input_data.append(img_tensor)"
      ],
      "metadata": {
        "id": "kj_YCQlXI2Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = np.array(input_data)\n",
        "input_data = torch.tensor(input_data)\n",
        "input_data = input_data.float()"
      ],
      "metadata": {
        "id": "JdWBaooHhKzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_data = []\n",
        "\n",
        "for val in spectrograms['Label']:\n",
        "  target_data.append(val)"
      ],
      "metadata": {
        "id": "NDPV-cF2gg1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_data = torch.tensor(target_data)\n",
        "target_data = target_data.float()"
      ],
      "metadata": {
        "id": "MGhsP3DKhsl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input = input_data[0:2000]\n",
        "train_target = target_data[0:2000]\n",
        "\n",
        "test_input = input_data[2000:]\n",
        "test_target = target_data[2000:]"
      ],
      "metadata": {
        "id": "AvS0TCCQjie9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(train_input, train_target)\n",
        "test_dataset = TensorDataset(test_input, test_target)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=1, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "F84_uVlJ5e4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(32768, 64)\n",
        "        self.fc2 = nn.Linear(64, 2)  # 2 output classes (binary classification)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32768)  # Flatten the feature maps\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lbCya1RSkVgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model, loss function, and optimizer\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    model.train()\n",
        "    for inputs, targets in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        inputs = inputs.to(torch.long)\n",
        "        targets = targets.to(torch.long)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "slyeaZCqkWK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_dataloader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_correct += (predicted == targets).sum().item()\n",
        "        total_samples += targets.size(0)\n",
        "\n",
        "accuracy = total_correct / total_samples\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "J_tMymb8lZAw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}